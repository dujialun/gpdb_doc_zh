<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd">
<topic id="testing">
  <title>测试和调试文本搜索</title>
  <shortdesc>本主题介绍可用于测试和调试搜索配置或配置中指定的单个解析器和词典的Greenplum数据库函数。
      </shortdesc>
  <body>
    <p>自定义文本搜索配置的行为很容易变得混乱。
        本节中描述的功能对于测试文本搜索对象非常有用。
        您可以单独测试完整配置或测试解析器和词典。
        </p>
    <p>本节包含以下子主题：<ul id="ul_m4h_h1x_4fb">
        <li><xref href="#testing/configuration" format="dita"/></li>
        <li><xref href="#testing/parser" format="dita"/></li>
        <li><xref href="#testing/dictionary" format="dita"/></li>
      </ul></p>
    <section id="configuration">
      <title>配置测试</title>
      <p>函数<codeph>ts_debug</codeph>允许轻松测试文本搜索配置。</p>
      <codeblock>ts_debug([<i>config</i> regconfig, ] <i>document</i> text,
         OUT <i>alias</i> text,
         OUT <i>description</i> text,
         OUT <i>token</i> text,
         OUT <i>dictionaries</i> regdictionary[],
         OUT <i>dictionary</i> regdictionary,
         OUT <i>lexemes</i> text[])
         returns setof record</codeblock>
      <p><codeph>ts_debug</codeph>显示有关解析器生成并由配置的字典处理的每个文档token的信息。
          它使用<codeph><i>config</i></codeph>指定的配置，如果省略该参数，则使用<codeph>default_text_search_config</codeph>。
          </p>
      <p><codeph>ts_debug</codeph>为解析器在文本中标识的每个token返回一行。
          返回的列是
        </p>
      <ul id="ul_uwp_yg1_lfb">
        <li><codeph><i>alias</i> text</codeph> — token类型的简称</li>
        <li><codeph><i>description</i> text</codeph> — token类型的描述</li>
        <li><codeph><i>token</i> text </codeph>— token文本</li>
        <li><codeph><i>dictionaries</i> regdictionary[]</codeph> — 由此token类型的配置选择的词典</li>
        <li><codeph><i>dictionary</i> regdictionary</codeph> — 识别token的字典，如果没有，则为<codeph>NULL</codeph></li>
        <li><codeph><i>lexemes</i> text[]</codeph> — 识别token的字典产生的词位，如果没有，则为<codeph>NULL</codeph>; 空数组(<codeph>{}</codeph>)表示它被识别为停止词</li>
      </ul>
      <p>这是一个简单的例子：</p>
      <codeblock>SELECT * FROM ts_debug('english','a fat  cat sat on a mat - it ate a fat rats');
   alias   |   description   | token |  dictionaries  |  dictionary  | lexemes 
-----------+-----------------+-------+----------------+--------------+---------
 asciiword | Word, all ASCII | a     | {english_stem} | english_stem | {}
 blank     | Space symbols   |       | {}             |              | 
 asciiword | Word, all ASCII | fat   | {english_stem} | english_stem | {fat}
 blank     | Space symbols   |       | {}             |              | 
 asciiword | Word, all ASCII | cat   | {english_stem} | english_stem | {cat}
 blank     | Space symbols   |       | {}             |              | 
 asciiword | Word, all ASCII | sat   | {english_stem} | english_stem | {sat}
 blank     | Space symbols   |       | {}             |              | 
 asciiword | Word, all ASCII | on    | {english_stem} | english_stem | {}
 blank     | Space symbols   |       | {}             |              | 
 asciiword | Word, all ASCII | a     | {english_stem} | english_stem | {}
 blank     | Space symbols   |       | {}             |              | 
 asciiword | Word, all ASCII | mat   | {english_stem} | english_stem | {mat}
 blank     | Space symbols   |       | {}             |              | 
 blank     | Space symbols   | -     | {}             |              | 
 asciiword | Word, all ASCII | it    | {english_stem} | english_stem | {}
 blank     | Space symbols   |       | {}             |              | 
 asciiword | Word, all ASCII | ate   | {english_stem} | english_stem | {ate}
 blank     | Space symbols   |       | {}             |              | 
 asciiword | Word, all ASCII | a     | {english_stem} | english_stem | {}
 blank     | Space symbols   |       | {}             |              | 
 asciiword | Word, all ASCII | fat   | {english_stem} | english_stem | {fat}
 blank     | Space symbols   |       | {}             |              | 
 asciiword | Word, all ASCII | rats  | {english_stem} | english_stem | {rat}</codeblock>
      <p>为了进行更广泛的演示，我们首先为英语创建一个<codeph>public.english</codeph>配置和Ispell字典：
        </p>
      <codeblock>CREATE TEXT SEARCH CONFIGURATION public.english ( COPY = pg_catalog.english );

CREATE TEXT SEARCH DICTIONARY english_ispell (
    TEMPLATE = ispell,
    DictFile = english,
    AffFile = english,
    StopWords = english
);

ALTER TEXT SEARCH CONFIGURATION public.english
   ALTER MAPPING FOR asciiword WITH english_ispell, english_stem;</codeblock>
      <codeblock>SELECT * FROM ts_debug('public.english','The Brightest supernovaes');
   alias   |   description   |    token    |         dictionaries          |   dictionary   |   lexemes   
-----------+-----------------+-------------+-------------------------------+----------------+-------------
 asciiword | Word, all ASCII | The         | {english_ispell,english_stem} | english_ispell | {}
 blank     | Space symbols   |             | {}                            |                | 
 asciiword | Word, all ASCII | Brightest   | {english_ispell,english_stem} | english_ispell | {bright}
 blank     | Space symbols   |             | {}                            |                | 
 asciiword | Word, all ASCII | supernovaes | {english_ispell,english_stem} | english_stem   | {supernova}</codeblock>
      <p>在此示例中，解析器将单词<codeph>Brightest</codeph>识别为<codeph>ASCII</codeph>字（别名<codeph>asciiword</codeph>）。
          对于此token类型，字典列表是<codeph>english_ispell</codeph>和<codeph>english_stem</codeph>。
          这个词被<codeph>english_ispell</codeph>识别，将其缩小为名词<codeph>bright</codeph>。
          <codeph>english_ispell</codeph>词典中不知道<codeph>supernovaes</codeph>这个词，所以它被传递到下一个词典，
          幸运的是，它被识别出来（事实上，<codeph>english_stem</codeph>是一个可以识别所有内容的Snowball词典;这就是为什么它放在词典列表的末尾）。
        </p>
      <p>单词<codeph>The</codeph>被<codeph>english_ispell</codeph>字典识别为停止词（<xref href="dictionaries.xml#dictionaries/stop-words"/>），不会被编入索引。
          这些空间也被丢弃，因为配置根本不为它们提供字典。
        </p>
      <p>您可以通过显式指定要查看的列来减小输出的宽度：</p>
      <codeblock>SELECT alias, token, dictionary, lexemes FROM ts_debug('public.english','The Brightest supernovaes'); 
  alias    |    token    |   dictionary   |    lexemes 
-----------+-------------+----------------+------------- 
 asciiword | The         | english_ispell | {} 
 blank     |             |                | 
 asciiword | Brightest   | english_ispell | {bright} 
 blank     |             |                | 
 asciiword | supernovaes | english_stem   | {supernova}</codeblock>
    </section>
    <section id="parser">
      <title>解析器测试</title>
      <p>以下函数允许直接测试文本搜索解析器。</p>
      <codeblock>ts_parse(<i>parser_name</i> text, <i>document</i> text,
         OUT <i>tokid</i> integer, OUT <i>token</i> text) returns setof record
ts_parse(<i>parser_oid</i> oid, <i>document</i> text,
         OUT <i>tokid</i> integer, OUT <i>token</i> text) returns setof record</codeblock>
      <p><codeph>ts_parse</codeph>解析给定文档并返回一系列记录，每个记录用于解析生成的每个token。
          每条记录都包含一个显示已分配token类型的<codeph>tokid</codeph>和一个<codeph>token</codeph>，是token的文本。
          例如：
          </p>
      <codeblock>SELECT * FROM ts_parse('default', '123 - a number');
 tokid | token
-------+--------
    22 | 123
    12 |
    12 | -
     1 | a
    12 |
     1 | number</codeblock>
      <pre>ts_token_type(<i>parser_name</i> text, OUT <i>tokid</i> integer,
              OUT <i>alias</i> text, OUT <i>description</i> text) returns setof record
ts_token_type(<i>parser_oid</i> oid, OUT <i>tokid</i> integer,
              OUT <i>alias</i> text, OUT <i>description</i> text) returns setof record</pre>
      <p><codeph>ts_token_type</codeph>返回一个表，该表描述指定解析器可识别的每种类型的token。
          对于每个token类型，该表给出了解析器用于标记该token类型的整数<codeph>tokid</codeph>，
          在配置命令中命名token类型的<codeph>alias</codeph>以及简短<codeph>description</codeph>。
          例如：
        </p>
      <codeblock>SELECT * FROM ts_token_type('default');
 tokid |      alias      |               description                
-------+-----------------+------------------------------------------
     1 | asciiword       | Word, all ASCII
     2 | word            | Word, all letters
     3 | numword         | Word, letters and digits
     4 | email           | Email address
     5 | url             | URL
     6 | host            | Host
     7 | sfloat          | Scientific notation
     8 | version         | Version number
     9 | hword_numpart   | Hyphenated word part, letters and digits
    10 | hword_part      | Hyphenated word part, all letters
    11 | hword_asciipart | Hyphenated word part, all ASCII
    12 | blank           | Space symbols
    13 | tag             | XML tag
    14 | protocol        | Protocol head
    15 | numhword        | Hyphenated word, letters and digits
    16 | asciihword      | Hyphenated word, all ASCII
    17 | hword           | Hyphenated word, all letters
    18 | url_path        | URL path
    19 | file            | File or path name
    20 | float           | Decimal notation
    21 | int             | Signed integer
    22 | uint            | Unsigned integer
    23 | entity          | XML entity</codeblock>
    </section>
    <section id="dictionary">
      <title>字典测试</title>
      <p><codeph>ts_lexize</codeph>函数有助于字典测试。</p>
      <pre>ts_lexize(<i>dictreg</i> dictionary, <i>token</i> text) returns text[]</pre>
      <p>如果字典已知输入token，则<codeph>ts_lexize</codeph>返回一个词位数组;
          如果字典已知该token但是它是一个停止词，则返回一个空数组;
          如果它是一个未知单词，则返回<codeph>NULL</codeph>。
        </p>
      <p>示例:</p>
      <codeblock>SELECT ts_lexize('english_stem', 'stars');
 ts_lexize
-----------
 {star}

SELECT ts_lexize('english_stem', 'a');
 ts_lexize
-----------
 {}</codeblock>
      <note><codeph>ts_lexize</codeph>函数需要单个token，而不是文本。
          这是一个令人困惑的案例：
          <codeblock>SELECT ts_lexize('thesaurus_astro','supernovae stars') is null;
 ?column?
----------
 t</codeblock><p>同义词词典<codeph>thesaurus_astro</codeph>确实知道短语<codeph>supernovae stars</codeph>，但<codeph>ts_lexize</codeph>失败，因为它不解析输入文本但将其视为单个token。
              使用<codeph>plainto_tsquery</codeph>或<codeph>to_tsvector</codeph>来测试同义词词典，例如：
              </p><codeblock>SELECT plainto_tsquery('supernovae stars');
 plainto_tsquery
-----------------
 'sn'</codeblock></note>
    </section>
  </body>
</topic>
