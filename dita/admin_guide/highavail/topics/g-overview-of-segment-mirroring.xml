<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic
  PUBLIC "-//OASIS//DTD DITA Composite//EN" "ditabase.dtd">
<topic id="topic3">
    <title>Segment镜像概述</title>
    <body>
        <p>当Greenplum数据库高可用性被启用时，有两种类型的Segment：<i>primary</i>Segment
            和<i>mirror</i>Segment。每个主Segment都有一个对应的镜像Segment。主Segment从
            Master接收请求来对该Segment的数据库做更改并且接着把那些更改复制到对应的镜像。
            如果主Segment变成不可用，镜像segment会切换为主segment，不可用的主segment会切换为
            镜像segment。故障出现时正在进行的事务会回滚并且必须重启数据库。接下来管理员必须恢复镜像segment，并
            允许镜像segment与当前主segment进行同步，最后需要交换主segment和镜像segment的角色，让他们处于自己
            最佳的角色状态。</p>
        <p>如果segment镜像未启用，当出现segment实例故障时，Greenplum数据库系统会关闭。管理员必须手工恢复所有
            失败的segment实例然后才能重新启动数据库。</p>
        <p>如果现有系统已经启用了segment镜像，当主segment实例正在生成一个快照时，主segment实例继续为用户提供服务。
            当主segment快照完成并向镜像segment实例部署时，主segment的变化也会被记录。当快照完全部署到镜像segment
            后，镜像segment会同步这些变化并采用WAL流复制的方式与主segment保持一致。Greenplum数据库的WAL复制使用
            <codeph>walsender</codeph>和<codeph>walreceiver</codeph>复制进程。
           <codeph>walsender</codeph>进程是主segment的进程。<codeph>walreceiver</codeph>进程是镜像segment
        的进程。</p>
        <p>当数据库变化出现时，日志捕获到该变化然后将变化流向镜像segment，以保证镜像与其对应的主segment一致。在WAL
            复制期间，数据库变化在被应用之前先写入日志中，以确保任何正在处理的数据的完整性。</p>
        <p>当Greenplum数据库检测到主segment故障时，WAL复制进程停止，镜像segment自动接管成为活动主segment。如果
            主segment活动时，镜像segment故障或变得不可访问，主segment会追踪数据库变化并记录在日志中，当镜像恢复后
            应用到镜像节点。有关segment故障检测和故障处理的详细信息，请见
                <xref href="g-detecting-a-failed-segment.xml#topic9"/>。</p>
        <p>Greenplum数据库系统表包含镜像和复制的详细信息。
           <ul id="ul_nn3_yjm_rdb">
                <li>系统表 <codeph><xref
                            href="../../../ref_guide/system_catalogs/gp_segment_configuration.xml#topic1"
                        /></codeph>包含主segment、镜像segment、主master和standby master实例的当前配置和
                    状态信息。</li>
                <li>系统视图<codeph><xref
                            href="../../../ref_guide/system_catalogs/gp_stat_replication.xml#topic1"
                /></codeph>包含Greenplum数据库master和segment镜像功能使用的<codeph>walsender</codeph>
                    进程的复制状态统计信息。</li>
            </ul></p>
        <section>
            <title>关于Segment镜像配置</title>
            <p>镜像segment实例可以根据配置的不同在集群主机中按不同的方式分布。作为最佳实践，主segment和它对应的镜像
                放在不同的主机上。每台主机必须有相同的主和镜像segment。当你使用Greenplum工具<codeph><xref
                        href="../../../utility_guide/admin_utilities/gpinitsystem.xml"/></codeph>或
                        <codeph><xref href="../../../utility_guide/admin_utilities/gpaddmirrors.xml"
                        /></codeph>创建segment镜像时，可以设定segment镜像方式：以分组的方式镜像（默认）或
                以打散的方式镜像。采用<codeph>gpaddmirrors</codeph>命令时，可以先创建<codeph>gpaddmirrors</codeph>
                配置文件，然后将文件放在命令行读取执行。</p>
            <p><i>以分组的方式镜像</i>是默认的镜像方式。该方式每台主机的主segment对应的镜像都整体放在另一台主机上，
                如果有一台主机故障，另外一台接管该主机服务的镜像所在的机器的活动segment数量便会翻倍。
                图表 <xref href="#topic3/fig_rrr_nt2_xt" format="dita"/>
                显示了以分组的方式配置segment镜像。</p>
            <!--<fig id="ki169754"><image href="../../graphics/mirrorsegs.png" placement="break" width="485px" height="135px"/></fig>-->
            <fig id="fig_rrr_nt2_xt">
                <title>以分组的方式在Greenplum数据库中分布镜像</title>
                <image href="../../graphics/group-mirroring.png" id="image_crm_pt2_xt"/>
            </fig>
            <p><i>以打散的方式镜像</i> 将每一个主机的镜像分散到多台主机上，保证每一个机器上至多只有一个
                镜像提升为主segment，这种方式可以防止单台主机故障后，另外的主机压力骤增。以打散方式镜像
                分布要求集群主机数量多于每台主机上segment的数量。图表<xref href="#topic3/fig_ew1_qgg_xt"
                    format="dita"/>显示了如何以打散的方式配置segment镜像。</p>
            <fig id="fig_ew1_qgg_xt">
                <title>以打散的方式在Greenplum数据库中分布镜像</title>
                <image href="../../graphics/spread-mirroring.png" id="image_zjm_wgg_xt"/>
            </fig>
        </section>
        <p> </p>
    </body>
</topic>
